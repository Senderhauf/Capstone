{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.isPipeline = exports.Pipeline = undefined;\n\nvar _extends2 = require(\"babel-runtime/helpers/extends\");\n\nvar _extends3 = _interopRequireDefault(_extends2);\n\nvar _getIterator2 = require(\"babel-runtime/core-js/get-iterator\");\n\nvar _getIterator3 = _interopRequireDefault(_getIterator2);\n\nvar _classCallCheck2 = require(\"babel-runtime/helpers/classCallCheck\");\n\nvar _classCallCheck3 = _interopRequireDefault(_classCallCheck2);\n\nvar _createClass2 = require(\"babel-runtime/helpers/createClass\");\n\nvar _createClass3 = _interopRequireDefault(_createClass2);\n\nvar _immutable = require(\"immutable\");\n\nvar _immutable2 = _interopRequireDefault(_immutable);\n\nvar _underscore = require(\"underscore\");\n\nvar _underscore2 = _interopRequireDefault(_underscore);\n\nvar _timeevent = require(\"./timeevent\");\n\nvar _timeevent2 = _interopRequireDefault(_timeevent);\n\nvar _indexedevent = require(\"./indexedevent\");\n\nvar _indexedevent2 = _interopRequireDefault(_indexedevent);\n\nvar _timerangeevent = require(\"./timerangeevent\");\n\nvar _timerangeevent2 = _interopRequireDefault(_timerangeevent);\n\nvar _timeseries = require(\"./timeseries\");\n\nvar _timeseries2 = _interopRequireDefault(_timeseries);\n\nvar _bounded = require(\"./io/bounded\");\n\nvar _bounded2 = _interopRequireDefault(_bounded);\n\nvar _collectionout = require(\"./io/collectionout\");\n\nvar _collectionout2 = _interopRequireDefault(_collectionout);\n\nvar _eventout = require(\"./io/eventout\");\n\nvar _eventout2 = _interopRequireDefault(_eventout);\n\nvar _stream = require(\"./io/stream\");\n\nvar _stream2 = _interopRequireDefault(_stream);\n\nvar _aggregator = require(\"./processors/aggregator\");\n\nvar _aggregator2 = _interopRequireDefault(_aggregator);\n\nvar _aligner = require(\"./processors/aligner\");\n\nvar _aligner2 = _interopRequireDefault(_aligner);\n\nvar _collapser = require(\"./processors/collapser\");\n\nvar _collapser2 = _interopRequireDefault(_collapser);\n\nvar _converter = require(\"./processors/converter\");\n\nvar _converter2 = _interopRequireDefault(_converter);\n\nvar _derivator = require(\"./processors/derivator\");\n\nvar _derivator2 = _interopRequireDefault(_derivator);\n\nvar _filler = require(\"./processors/filler\");\n\nvar _filler2 = _interopRequireDefault(_filler);\n\nvar _filter = require(\"./processors/filter\");\n\nvar _filter2 = _interopRequireDefault(_filter);\n\nvar _mapper = require(\"./processors/mapper\");\n\nvar _mapper2 = _interopRequireDefault(_mapper);\n\nvar _offset = require(\"./processors/offset\");\n\nvar _offset2 = _interopRequireDefault(_offset);\n\nvar _processor = require(\"./processors/processor\");\n\nvar _processor2 = _interopRequireDefault(_processor);\n\nvar _selector = require(\"./processors/selector\");\n\nvar _selector2 = _interopRequireDefault(_selector);\n\nvar _taker = require(\"./processors/taker\");\n\nvar _taker2 = _interopRequireDefault(_taker);\n\nfunction _interopRequireDefault(obj) {\n  return obj && obj.__esModule ? obj : {\n    default: obj\n  };\n}\n/**\n * A runner is used to extract the chain of processing operations\n * from a Pipeline given an Output. The idea here is to traverse\n * back up the Pipeline(s) and build an execution chain.\n *\n * When the runner is started, events from the \"in\" are streamed\n * into the execution chain and outputed into the \"out\".\n *\n * Rebuilding in this way enables us to handle connected pipelines:\n *\n *                     |--\n *  in --> pipeline ---.\n *                     |----pipeline ---| -> out\n *\n * The runner breaks this into the following for execution:\n *\n *   _input        - the \"in\" or from() bounded input of\n *                   the upstream pipeline\n *   _processChain - the process nodes in the pipelines\n *                   leading to the out\n *   _output       - the supplied output destination for\n *                   the batch process\n *\n * NOTE: There's no current way to merge multiple sources, though\n *       a time series has a TimeSeries.merge() static method for\n *       this purpose.\n */\n// Processors\n// I/O\n\n/*\n *  Copyright (c) 2016-2017, The Regents of the University of California,\n *  through Lawrence Berkeley National Laboratory (subject to receipt\n *  of any required approvals from the U.S. Dept. of Energy).\n *  All rights reserved.\n *\n *  This source code is licensed under the BSD-style license found in the\n *  LICENSE file in the root directory of this source tree.\n */\n\n\nvar Runner = function () {\n  /**\n   * Create a new batch runner.\n   * @param  {Pipeline} pipeline The pipeline to run\n   * @param  {PipelineOut} output   The output driving this runner\n   */\n  function Runner(pipeline, output) {\n    var _this = this;\n\n    (0, _classCallCheck3.default)(this, Runner);\n    this._output = output;\n    this._pipeline = pipeline; //\n    // We use the pipeline's chain() function to walk the\n    // DAG back up the tree to the \"in\" to:\n    // 1) assemble a list of process nodes that feed into\n    //    this pipeline, the processChain\n    // 2) determine the _input\n    //\n    // TODO: we do not currently support merging, so this is\n    // a linear chain.\n    //\n\n    var processChain = [];\n\n    if (pipeline.last()) {\n      processChain = pipeline.last().chain();\n      this._input = processChain[0].pipeline().in();\n    } else {\n      this._input = pipeline.in();\n    } //\n    // Using the list of nodes in the tree that will be involved in\n    // our processing we can build an execution chain. This is the\n    // chain of processor clones, linked together, for our specific\n    // processing pipeline. We run this execution chain later by\n    // evoking start().\n    //\n\n\n    this._executionChain = [this._output];\n    var prev = this._output;\n    processChain.forEach(function (p) {\n      if (p instanceof _processor2.default) {\n        var processor = p.clone();\n        if (prev) processor.addObserver(prev);\n\n        _this._executionChain.push(processor);\n\n        prev = processor;\n      }\n    });\n  }\n  /**\n   * Start the runner\n   * @param  {Boolean} force Force a flush at the end of the batch source\n   *                         to cause any buffers to emit.\n   */\n\n\n  (0, _createClass3.default)(Runner, [{\n    key: \"start\",\n    value: function start() {\n      var force = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false; // Clear any results ready for the run\n\n      this._pipeline.clearResults(); //\n      // The head is the first process node in the execution chain.\n      // To process the source through the execution chain we add\n      // each event from the input to the head.\n      //\n\n\n      var head = this._executionChain.pop();\n\n      var _iteratorNormalCompletion = true;\n      var _didIteratorError = false;\n      var _iteratorError = undefined;\n\n      try {\n        for (var _iterator = (0, _getIterator3.default)(this._input.events()), _step; !(_iteratorNormalCompletion = (_step = _iterator.next()).done); _iteratorNormalCompletion = true) {\n          var e = _step.value;\n          head.addEvent(e);\n        } //\n        // The runner indicates that it is finished with the bounded\n        // data by sending a flush() call down the chain. If force is\n        // set to false (the default) this is never called.\n        //\n\n      } catch (err) {\n        _didIteratorError = true;\n        _iteratorError = err;\n      } finally {\n        try {\n          if (!_iteratorNormalCompletion && _iterator.return) {\n            _iterator.return();\n          }\n        } finally {\n          if (_didIteratorError) {\n            throw _iteratorError;\n          }\n        }\n      }\n\n      if (force) {\n        head.flush();\n      }\n    }\n  }]);\n  return Runner;\n}();\n/**\n * A pipeline manages a processing chain, for either batch or stream processing\n * of collection data.\n */\n\n\nvar Pipeline = function () {\n  /**\n   * Build a new Pipeline.\n   *\n   * @param  {Pipeline|Immutable.Map|null} [arg] May be either:\n   *  * a Pipeline (copy contructor)\n   *  * an Immutable.Map, in which case the internal state of the\n   *    Pipeline will be contructed from the Map\n   *  * not specified\n   *\n   * Usually you would initialize a Pipeline using the factory\n   * function, rather than this object directly with `new`.\n   *\n   * @example\n   * ```\n   * import { Pipeline } from \"pondjs\";\n   * const p = Pipeline()...`\n   * ```\n   *\n   * @return {Pipeline} The Pipeline\n   */\n  function Pipeline(arg) {\n    (0, _classCallCheck3.default)(this, Pipeline);\n\n    if (arg instanceof Pipeline) {\n      var other = arg;\n      this._d = other._d;\n    } else if (arg instanceof _immutable2.default.Map) {\n      this._d = arg;\n    } else {\n      this._d = new _immutable2.default.Map({\n        type: null,\n        in: null,\n        first: null,\n        last: null,\n        groupBy: function groupBy() {\n          return \"\";\n        },\n        windowType: \"global\",\n        windowDuration: null,\n        emitOn: \"eachEvent\"\n      });\n    }\n\n    this._results = [];\n  } //\n  // Accessors to the current Pipeline state\n  //\n\n\n  (0, _createClass3.default)(Pipeline, [{\n    key: \"in\",\n    value: function _in() {\n      return this._d.get(\"in\");\n    }\n  }, {\n    key: \"mode\",\n    value: function mode() {\n      return this._d.get(\"mode\");\n    }\n  }, {\n    key: \"first\",\n    value: function first() {\n      return this._d.get(\"first\");\n    }\n  }, {\n    key: \"last\",\n    value: function last() {\n      return this._d.get(\"last\");\n    }\n  }, {\n    key: \"getWindowType\",\n    value: function getWindowType() {\n      return this._d.get(\"windowType\");\n    }\n  }, {\n    key: \"getWindowDuration\",\n    value: function getWindowDuration() {\n      return this._d.get(\"windowDuration\");\n    }\n  }, {\n    key: \"getGroupBy\",\n    value: function getGroupBy() {\n      return this._d.get(\"groupBy\");\n    }\n  }, {\n    key: \"getEmitOn\",\n    value: function getEmitOn() {\n      return this._d.get(\"emitOn\");\n    } //\n    // Results\n    //\n\n  }, {\n    key: \"clearResults\",\n    value: function clearResults() {\n      this._resultsDone = false;\n      this._results = null;\n    }\n  }, {\n    key: \"addResult\",\n    value: function addResult(arg1, arg2) {\n      if (!this._results) {\n        if (_underscore2.default.isString(arg1) && arg2) {\n          this._results = {};\n        } else {\n          this._results = [];\n        }\n      }\n\n      if (_underscore2.default.isString(arg1) && arg2) {\n        this._results[arg1] = arg2;\n      } else {\n        this._results.push(arg1);\n      }\n\n      this._resultsDone = false;\n    }\n  }, {\n    key: \"resultsDone\",\n    value: function resultsDone() {\n      this._resultsDone = true;\n    } //\n    // Pipeline mutations\n    //\n\n    /**\n     * Setting the In for the Pipeline returns a new Pipeline\n     *\n     * @private\n     */\n\n  }, {\n    key: \"_setIn\",\n    value: function _setIn(input) {\n      var mode = void 0;\n      var source = input;\n\n      if (input instanceof _timeseries2.default) {\n        mode = \"batch\";\n        source = input.collection();\n      } else if (input instanceof _bounded2.default) {\n        mode = \"batch\";\n      } else if (input instanceof _stream2.default) {\n        mode = \"stream\";\n      } else {\n        throw new Error(\"Unknown input type\", input);\n      }\n\n      var d = this._d.withMutations(function (map) {\n        map.set(\"in\", source).set(\"mode\", mode);\n      });\n\n      return new Pipeline(d);\n    }\n    /**\n     * Set the first processing node pointed to, returning\n     * a new Pipeline. The original pipeline will still point\n     * to its orginal processing node.\n     *\n     * @private\n     */\n\n  }, {\n    key: \"_setFirst\",\n    value: function _setFirst(n) {\n      var d = this._d.set(\"first\", n);\n\n      return new Pipeline(d);\n    }\n    /**\n     * Set the last processing node pointed to, returning\n     * a new Pipeline. The original pipeline will still point\n     * to its orginal processing node.\n     *\n     * @private\n     */\n\n  }, {\n    key: \"_setLast\",\n    value: function _setLast(n) {\n      var d = this._d.set(\"last\", n);\n\n      return new Pipeline(d);\n    }\n    /**\n     * @private\n     */\n\n  }, {\n    key: \"_append\",\n    value: function _append(processor) {\n      var first = this.first();\n      var last = this.last();\n      if (!first) first = processor;\n      if (last) last.addObserver(processor);\n      last = processor;\n\n      var d = this._d.withMutations(function (map) {\n        map.set(\"first\", first).set(\"last\", last);\n      });\n\n      return new Pipeline(d);\n    }\n  }, {\n    key: \"_chainPrev\",\n    value: function _chainPrev() {\n      return this.last() || this;\n    } //\n    // Pipeline state chained methods\n    //\n\n    /**\n     * Set the window, returning a new Pipeline. A new window will\n     * have a type and duration associated with it. Current available\n     * types are:\n     *   * fixed (e.g. every 5m)\n     *   * calendar based windows (e.g. every month)\n     *\n     * Windows are a type of grouping. Typically you'd define a window\n     * on the pipeline before doing an aggregation or some other operation\n     * on the resulting grouped collection. You can combine window-based\n     * grouping with key-grouping (see groupBy()).\n     *\n     * There are several ways to define a window. The general format is\n     * an options object containing a `type` field and a `duration` field.\n     *\n     * Currently the only accepted type is `fixed`, but others are planned.\n     * For duration, this is a duration string, for example \"30s\" or \"1d\".\n     * Supported are: seconds (s), minutes (m), hours (h) and days (d).\n     *\n     * If no arg is supplied, the window type is set to 'global' and there\n     * is no duration.\n     *\n     * There is also a short-cut notation for a fixed window or a calendar\n     * window. Simply supplying the duration string (\"30s\" for example) will\n     * result in a `fixed` window type with the supplied duration.\n     *\n     * Calendar types are specified by simply specifying \"daily\", \"monthly\"\n     * or \"yearly\".\n     *\n     * @param {string|object} w Window or duration - See above\n     * @return {Pipeline} The Pipeline\n     */\n\n  }, {\n    key: \"windowBy\",\n    value: function windowBy(w) {\n      var type = void 0,\n          duration = void 0;\n\n      if (_underscore2.default.isString(w)) {\n        if (w === \"daily\" || w === \"monthly\" || w === \"yearly\") {\n          type = w;\n        } else {\n          // assume fixed window with size w\n          type = \"fixed\";\n          duration = w;\n        }\n      } else if (_underscore2.default.isObject(w)) {\n        type = w.type;\n        duration = w.duration;\n      } else {\n        type = \"global\";\n        duration = null;\n      }\n\n      var d = this._d.withMutations(function (map) {\n        map.set(\"windowType\", type).set(\"windowDuration\", duration);\n      });\n\n      return new Pipeline(d);\n    }\n    /**\n     * Remove windowing from the Pipeline. This will\n     * return the pipeline to no window grouping. This is\n     * useful if you have first done some aggregated by\n     * some window size and then wish to collect together\n     * the all resulting events.\n     *\n     * @return {Pipeline} The Pipeline\n     */\n\n  }, {\n    key: \"clearWindow\",\n    value: function clearWindow() {\n      return this.windowBy();\n    }\n    /**\n     * Sets a new key grouping. Returns a new Pipeline.\n     *\n     * Grouping is a state set on the Pipeline. Operations downstream\n     * of the group specification will use that state. For example, an\n     * aggregation would occur over any grouping specified. You can\n     * combine a key grouping with windowing (see windowBy()).\n     *\n     * Note: the key, if it is a field path, is not a list of multiple\n     * columns, it is the path to a single column to pull group by keys\n     * from. For example, a column called 'status' that contains the\n     * values 'OK' and 'FAIL' - then the key would be 'status' and two\n     * collections OK and FAIL will be generated.\n     *\n     * @param {function|array|string}   k   The key to group by.\n     *                                      You can groupBy using a function\n     *                                      `(event) => return key`,\n     *                                      a field path (a field name, or dot\n     *                                      delimitted path to a field),\n     *                                      or a array of field paths.\n     *\n     * @return {Pipeline}                   The Pipeline\n     */\n\n  }, {\n    key: \"groupBy\",\n    value: function groupBy(k) {\n      var grp = void 0;\n      var groupBy = k || \"value\";\n\n      if (_underscore2.default.isFunction(groupBy)) {\n        // group using a user defined function\n        // (event) => key\n        grp = groupBy;\n      } else if (_underscore2.default.isArray(groupBy)) {\n        // group by several column values\n        grp = function grp(e) {\n          return _underscore2.default.map(groupBy, function (c) {\n            return \"\" + e.get(c);\n          }).join(\"::\");\n        };\n      } else if (_underscore2.default.isString(groupBy)) {\n        // group by a column value\n        grp = function grp(e) {\n          return \"\" + e.get(groupBy);\n        };\n      } else {\n        // Reset to no grouping\n        grp = function grp() {\n          return \"\";\n        };\n      }\n\n      var d = this._d.withMutations(function (map) {\n        map.set(\"groupBy\", grp);\n      });\n\n      return new Pipeline(d);\n    }\n    /**\n     * Remove the grouping from the pipeline. In other words\n     * recombine the events.\n     *\n     * @return {Pipeline} The Pipeline\n     */\n\n  }, {\n    key: \"clearGroupBy\",\n    value: function clearGroupBy() {\n      return this.groupBy();\n    }\n    /**\n     * Sets the condition under which an accumulated collection will\n     * be emitted. If specified before an aggregation this will control\n     * when the resulting event will be emitted relative to the\n     * window accumulation. Current options are:\n     *  * to emit on every event, or\n     *  * just when the collection is complete, or\n     *  * when a flush signal is received, either manually calling done(),\n     *    or at the end of a bounded source\n     *\n     * The difference will depend on the output you want, how often\n     * you want to get updated, and if you need to get a partial state.\n     * There's currently no support for late data or watermarks. If an\n     * event passes comes in after a collection window, that collection\n     * is considered finished.\n     *\n     * @param {string} trigger A string indicating how to trigger a\n     * Collection should be emitted. May be:\n     *     * \"eachEvent\" - when a new event comes in, all currently\n     *                     maintained collections will emit their result\n     *     * \"discard\"   - when a collection is to be discarded,\n     *                     first it will emit. But only then.\n     *     * \"flush\"     - when a flush signal is received\n     *\n     * @return {Pipeline} The Pipeline\n     */\n\n  }, {\n    key: \"emitOn\",\n    value: function emitOn(trigger) {\n      var d = this._d.set(\"emitOn\", trigger);\n\n      return new Pipeline(d);\n    } //\n    // I/O\n    //\n\n    /**\n     * The source to get events from. The source needs to be able to\n     * iterate its events using `for..of` loop for bounded Ins, or\n     * be able to emit() for unbounded Ins. The actual batch, or stream\n     * connection occurs when an output is defined with `to()`.\n     *\n     * Pipelines can be chained together since a source may be another\n     * Pipeline.\n     *\n     * @param {Bounded|Stream} src The source for the Pipeline\n     * @return {Pipeline} The Pipeline\n     */\n\n  }, {\n    key: \"from\",\n    value: function from(src) {\n      return this._setIn(src);\n    }\n    /**\n     * Directly return the results from the processor rather than\n     * feeding to a callback. This breaks the chain, causing a result to\n     * be returned (the array of events) rather than a reference to the\n     * Pipeline itself. This function is only available for sync batch\n     * processing.\n     *\n     * @return {array|map}     Returns the _results attribute from a Pipeline\n     *                         object after processing. Will contain Collection\n     *                         objects.\n     */\n\n  }, {\n    key: \"toEventList\",\n    value: function toEventList() {\n      return this.to(_eventout2.default);\n    }\n    /**\n     * Directly return the results from the processor rather than\n     * passing a callback in. This breaks the chain, causing a result to\n     * be returned (the collections) rather than a reference to the\n     * Pipeline itself. This function is only available for sync batch\n     * processing.\n     *\n     * @return {array|map}     Returns the _results attribute from a Pipeline\n     *                         object after processing. Will contain Collection\n     *                         objects.\n     */\n\n  }, {\n    key: \"toKeyedCollections\",\n    value: function toKeyedCollections() {\n      var result = this.to(_collectionout2.default);\n\n      if (result) {\n        return result;\n      } else {\n        return {};\n      }\n    }\n    /**\n     * Sets up the destination sink for the pipeline.\n     *\n     * For a batch mode connection, i.e. one with a Bounded source,\n     * the output is connected to a clone of the parts of the Pipeline dependencies\n     * that lead to this output. This is done by a Runner. The source input is\n     * then iterated over to process all events into the pipeline and though to the Out.\n     *\n     * For stream mode connections, the output is connected and from then on\n     * any events added to the input will be processed down the pipeline to\n     * the out.\n     *\n     * @example\n     * ```\n     * const p = Pipeline()\n     *  ...\n     *  .to(EventOut, {}, event => {\n     *      result[`${event.index()}`] = event;\n     *  });\n     * ```\n     * @return {Pipeline} The Pipeline\n     */\n\n  }, {\n    key: \"to\",\n    value: function to(arg1, arg2, arg3) {\n      var Out = arg1;\n      var observer = void 0;\n      var options = {};\n\n      if (_underscore2.default.isFunction(arg2)) {\n        observer = arg2;\n      } else if (_underscore2.default.isObject(arg2)) {\n        options = arg2;\n        observer = arg3;\n      }\n\n      if (!this.in()) {\n        throw new Error(\"Tried to eval pipeline without a In. Missing from() in chain?\");\n      }\n\n      var out = new Out(this, options, observer);\n\n      if (this.mode() === \"batch\") {\n        var runner = new Runner(this, out);\n        runner.start(true);\n\n        if (this._resultsDone && !observer) {\n          return this._results;\n        }\n      } else if (this.mode() === \"stream\") {\n        var _out = new Out(this, options, observer);\n\n        if (this.first()) {\n          this.in().addObserver(this.first());\n        }\n\n        if (this.last()) {\n          this.last().addObserver(_out);\n        } else {\n          this.in().addObserver(_out);\n        }\n      }\n\n      return this;\n    }\n    /**\n     * Outputs the count of events\n     *\n     * @param  {function}  observer The callback function. This will be\n     *                              passed the count, the windowKey and\n     *                              the groupByKey\n     * @param  {Boolean} force    Flush at the end of processing batch\n     *                            events, output again with possibly partial\n     *                            result.\n     * @return {Pipeline} The Pipeline\n     */\n\n  }, {\n    key: \"count\",\n    value: function count(observer) {\n      var force = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;\n      return this.to(_collectionout2.default, function (collection, windowKey, groupByKey) {\n        observer(collection.size(), windowKey, groupByKey);\n      }, force);\n    } //\n    // Processors\n    //\n\n    /**\n     * Processor to offset a set of fields by a value. Mostly used for\n     * testing processor and pipeline operations with a simple operation.\n     *\n     * @param  {number} by              The amount to offset by\n     * @param  {string|array} fieldSpec The field(s)\n     *\n     * @return {Pipeline}               The modified Pipeline\n     */\n\n  }, {\n    key: \"offsetBy\",\n    value: function offsetBy(by, fieldSpec) {\n      var p = new _offset2.default(this, {\n        by: by,\n        fieldSpec: fieldSpec,\n        prev: this._chainPrev()\n      });\n      return this._append(p);\n    }\n    /**\n     * Uses the current Pipeline windowing and grouping\n     * state to build collections of events and aggregate them.\n     *\n     * `IndexedEvent`s will be emitted out of the aggregator based\n     * on the `emitOn` state of the Pipeline.\n     *\n     * To specify what part of the incoming events should\n     * be aggregated together you specify a `fields`\n     * object. This is a map from fieldName to operator.\n     *\n     * @example\n     *\n     * ```\n     * import { Pipeline, EventOut, functions } from \"pondjs\";\n     * const { avg } = functions;\n     *\n     * const p = Pipeline()\n     *   .from(input)\n     *   .windowBy(\"1h\")           // 1 day fixed windows\n     *   .emitOn(\"eachEvent\")      // emit result on each event\n     *   .aggregate({\n     *      in_avg: {in: avg},\n     *      out_avg: {in: avg}\n     *   })\n     *   .asTimeEvents()\n     *   .to(EventOut, {}, event => {\n     *      result[`${event.index()}`] = event; // Result\n     *   });\n     * ```\n     *\n     * @param  {object} fields Fields and operators to be aggregated\n     *\n     * @return {Pipeline} The Pipeline\n     */\n\n  }, {\n    key: \"aggregate\",\n    value: function aggregate(fields) {\n      var p = new _aggregator2.default(this, {\n        fields: fields,\n        prev: this._chainPrev()\n      });\n      return this._append(p);\n    }\n    /**\n     * Converts incoming TimeRangeEvents or IndexedEvents to\n     * TimeEvents. This is helpful since some processors,\n     * especially aggregators, will emit TimeRangeEvents or\n     * IndexedEvents, which may be unsuitable for some applications.\n     *\n     * @param  {object} options To convert to an TimeEvent you need\n     * to convert a time range to a single time. There are three options:\n     *  1. use the beginning time (options = {alignment: \"lag\"})\n     *  2. use the center time (options = {alignment: \"center\"})\n     *  3. use the end time (options = {alignment: \"lead\"})\n     *\n     * @return {Pipeline} The Pipeline\n     */\n\n  }, {\n    key: \"asTimeEvents\",\n    value: function asTimeEvents(options) {\n      var type = _timeevent2.default;\n      var p = new _converter2.default(this, (0, _extends3.default)({\n        type: type\n      }, options, {\n        prev: this._chainPrev()\n      }));\n      return this._append(p);\n    }\n    /**\n     * Map the event stream using an operator\n     *\n     * @param  {function} op A function that returns a new Event\n     *\n     * @return {Pipeline} The Pipeline\n     */\n\n  }, {\n    key: \"map\",\n    value: function map(op) {\n      var p = new _mapper2.default(this, {\n        op: op,\n        prev: this._chainPrev()\n      });\n      return this._append(p);\n    }\n    /**\n     * Filter the event stream using an operator\n     *\n     * @param  {function} op A function that returns true or false\n     *\n     * @return {Pipeline} The Pipeline\n     */\n\n  }, {\n    key: \"filter\",\n    value: function filter(op) {\n      var p = new _filter2.default(this, {\n        op: op,\n        prev: this._chainPrev()\n      });\n      return this._append(p);\n    }\n    /**\n     * Select a subset of columns\n     *\n     * @param {string|array} fieldSpec  Column or columns to look up. If you need\n     *                                  to retrieve multiple deep nested values that\n     *                                  ['can.be', 'done.with', 'this.notation'].\n     *                                  A single deep value with a string.like.this.\n     *                                  If not supplied, the 'value' column will be used.\n     *\n     * @return {Pipeline} The Pipeline\n     */\n\n  }, {\n    key: \"select\",\n    value: function select(fieldSpec) {\n      var p = new _selector2.default(this, {\n        fieldSpec: fieldSpec,\n        prev: this._chainPrev()\n      });\n      return this._append(p);\n    }\n    /**\n     * Collapse a subset of columns using a reducer function\n     *\n     * @example\n     *\n     * ```\n     *  const timeseries = new TimeSeries(inOutData);\n     *  Pipeline()\n     *      .from(timeseries)\n     *      .collapse([\"in\", \"out\"], \"in_out_sum\", sum)\n     *      .emitOn(\"flush\")\n     *      .to(CollectionOut, c => {\n     *           const ts = new TimeSeries({name: \"subset\", collection: c});\n     *           ...\n     *      }, true);\n     * ```\n     * @param {string|array} fieldSpecList  Column or columns to collapse. If you need\n     *                                      to retrieve multiple deep nested values that\n     *                                      ['can.be', 'done.with', 'this.notation'].\n     * @param {string}       name       The resulting output column's name\n     * @param {function}     reducer    Function to use to do the reduction\n     * @param {boolean}      append     Add the new column to the existing ones,\n     *                                  or replace them.\n     *\n     * @return {Pipeline}               The Pipeline\n     */\n\n  }, {\n    key: \"collapse\",\n    value: function collapse(fieldSpecList, name, reducer, append) {\n      var p = new _collapser2.default(this, {\n        fieldSpecList: fieldSpecList,\n        name: name,\n        reducer: reducer,\n        append: append,\n        prev: this._chainPrev()\n      });\n      return this._append(p);\n    }\n    /**\n     * Take the data in this event steam and \"fill\" any missing\n     * or invalid values. This could be setting `null` values to `0`\n     * so mathematical operations will succeed, interpolate a new\n     * value, or pad with the previously given value.\n     *\n     * If one wishes to limit the number of filled events in the result\n     * set, use Pipeline.keep() in the chain. See: TimeSeries.fill()\n     * for an example.\n     *\n     * Fill takes a single arg `options` which should be composed of:\n     *  * fieldSpec - Column or columns to look up. If you need\n     *                to retrieve multiple deep nested values that\n     *                ['can.be', 'done.with', 'this.notation'].\n     *                A single deep value with a string.like.this.\n     *  * method -    Filling method: zero | linear | pad\n     *\n     * @return {Pipeline}               The Pipeline\n     */\n\n  }, {\n    key: \"fill\",\n    value: function fill(_ref) {\n      var _ref$fieldSpec = _ref.fieldSpec,\n          fieldSpec = _ref$fieldSpec === undefined ? null : _ref$fieldSpec,\n          _ref$method = _ref.method,\n          method = _ref$method === undefined ? \"linear\" : _ref$method,\n          _ref$limit = _ref.limit,\n          limit = _ref$limit === undefined ? null : _ref$limit;\n\n      var prev = this._chainPrev();\n\n      return this._append(new _filler2.default(this, {\n        fieldSpec: fieldSpec,\n        method: method,\n        limit: limit,\n        prev: prev\n      }));\n    }\n  }, {\n    key: \"align\",\n    value: function align(fieldSpec, window, method, limit) {\n      var prev = this._chainPrev();\n\n      return this._append(new _aligner2.default(this, {\n        fieldSpec: fieldSpec,\n        window: window,\n        method: method,\n        limit: limit,\n        prev: prev\n      }));\n    }\n  }, {\n    key: \"rate\",\n    value: function rate(fieldSpec) {\n      var allowNegative = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;\n      var p = new _derivator2.default(this, {\n        fieldSpec: fieldSpec,\n        allowNegative: allowNegative,\n        prev: this._chainPrev()\n      });\n      return this._append(p);\n    }\n    /**\n     * Take events up to the supplied limit, per key.\n     *\n     * @param  {number} limit Integer number of events to take\n     *\n     * @return {Pipeline} The Pipeline\n     */\n\n  }, {\n    key: \"take\",\n    value: function take(limit) {\n      var p = new _taker2.default(this, {\n        limit: limit,\n        prev: this._chainPrev()\n      });\n      return this._append(p);\n    }\n    /**\n     * Converts incoming Events or IndexedEvents to TimeRangeEvents.\n     *\n     * @param {object} options To convert from an Event you need\n     * to convert a single time to a time range. To control this you\n     * need to specify the duration of that time range, along with\n     * the positioning (alignment) of the time range with respect to\n     * the time stamp of the Event.\n     *\n     * There are three option for alignment:\n     *  1. time range will be in front of the timestamp (options = {alignment: \"front\"})\n     *  2. time range will be centered on the timestamp (options = {alignment: \"center\"})\n     *  3. time range will be positoned behind the timestamp (options = {alignment: \"behind\"})\n     *\n     * The duration is of the form \"1h\" for one hour, \"30s\" for 30 seconds and so on.\n     *\n     * @return {Pipeline} The Pipeline\n     */\n\n  }, {\n    key: \"asTimeRangeEvents\",\n    value: function asTimeRangeEvents(options) {\n      var type = _timerangeevent2.default;\n      var p = new _converter2.default(this, (0, _extends3.default)({\n        type: type\n      }, options, {\n        prev: this._chainPrev()\n      }));\n      return this._append(p);\n    }\n    /**\n     * Converts incoming Events to IndexedEvents.\n     *\n     * Note: It isn't possible to convert TimeRangeEvents to IndexedEvents.\n     *\n     * @param {Object} options            An object containing the conversion\n     * options. In this case the duration string of the Index is expected.\n     * @param {string} options.duration   The duration string is of the form \"1h\" for one hour, \"30s\"\n     * for 30 seconds and so on.\n     *\n     * @return {Pipeline} The Pipeline\n     */\n\n  }, {\n    key: \"asIndexedEvents\",\n    value: function asIndexedEvents(options) {\n      var type = _indexedevent2.default;\n      var p = new _converter2.default(this, (0, _extends3.default)({\n        type: type\n      }, options, {\n        prev: this._chainPrev()\n      }));\n      return this._append(p);\n    }\n  }]);\n  return Pipeline;\n}();\n\nfunction pipeline(args) {\n  return new Pipeline(args);\n}\n\nfunction is(p) {\n  return p instanceof Pipeline;\n}\n\nexports.Pipeline = pipeline;\nexports.isPipeline = is;","map":null,"metadata":{},"sourceType":"script"}